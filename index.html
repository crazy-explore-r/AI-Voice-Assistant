<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>AI Voice Agent (MVP)</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 600px;
            margin: 0 auto;
            padding: 20px;
        }

        button {
            background-color: #4CAF50;
            color: white;
            padding: 10px 15px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
        }

        button:hover {
            background-color: #45a049;
        }

        .status {
            margin-top: 20px;
            padding: 10px;
            border-radius: 5px;
        }

        #userText,
        #aiText {
            background-color: #f1f1f1;
            padding: 10px;
            border-radius: 5px;
            min-height: 20px;
        }

        audio {
            display: none;
            margin-top: 20px;
        }
    </style>
</head>

<body>
    <h2>üéôÔ∏è Talk to AI (Push to Talk)</h2>
    <p>Hold the button, speak, and release to ask your question. The AI will reply with voice.</p>
    <button id="pushToTalkBtn">Push to Talk</button>
    <audio id="audioPlayback" controls style="display:none; margin-top:20px;"></audio>
    <div class="status">
        <p><strong>Status:</strong> <span id="status">Ready</span></p>
        <p><strong>Transcription:</strong> <span id="userText">...</span></p>
        <p><strong>AI says:</strong> <span id="aiText">...</span></p>
    </div>
    <div id="debug" style="margin-top: 20px; font-size: 12px; color: #666;"></div>

    <script>
        // 1. Speech to Text - Check if the browser supports SpeechRecognition
        if (!('SpeechRecognition' in window || 'webkitSpeechRecognition' in window)) {
            alert("Your browser doesn't support speech recognition. Please try Chrome or Edge.");
        }

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.lang = 'en-US';
        recognition.interimResults = false;

        recognition.onresult = function (event) {
            const userSpeech = event.results[0][0].transcript;
            document.getElementById("status").textContent = "Processing...";
            document.getElementById("userText").textContent = userSpeech;
            console.log("Speech recognized:", userSpeech);
            document.getElementById("debug").textContent += "Speech recognized: " + userSpeech + "\n";
            sendToGPT(userSpeech);
        };

        recognition.onerror = function (event) {
            console.error("Speech recognition error:", event.error);
            document.getElementById("userText").textContent = "Error: " + event.error + ". Try again.";
        };

        recognition.onend = function () {
            console.log("Speech recognition ended");
        };

        function startListening() {
            document.getElementById("status").textContent = "Listening...";
            document.getElementById("userText").textContent = "...";
            document.getElementById("debug").textContent = ""; // Clear debug info

            try {
                recognition.start();
            } catch (error) {
                console.error("Error starting speech recognition:", error);
                document.getElementById("status").textContent = "Error";
                document.getElementById("userText").textContent = "Error starting: " + error.message;
                document.getElementById("debug").textContent = "Full error: " + JSON.stringify(error);
            }
        }

        // 2. Send to GPT-4o
        async function sendToGPT(message) {
            document.getElementById("aiText").textContent = "Thinking...";
            try {
                console.log("Sending to backend server:", message);
                const response = await fetch("/api/chat", {
                    method: "POST",
                    headers: {
                        "Content-Type": "application/json"
                    },
                    body: JSON.stringify({ message })
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(`API error: ${response.status} - ${JSON.stringify(errorData)}`);
                }

                const data = await response.json();
                console.log("OpenAI response:", data);

                if (data.choices && data.choices[0] && data.choices[0].message) {
                    const reply = data.choices[0].message.content;
                    document.getElementById("aiText").textContent = reply;
                    speak(reply);
                } else {
                    throw new Error("Unexpected API response format");
                }
            } catch (error) {
                console.error("Error calling API:", error);
                document.getElementById("aiText").textContent = "Error: " + error.message;
            }
        }

        // 3. Text to Speech
        function speak(text) {
            if (!('speechSynthesis' in window)) {
                console.error("Browser doesn't support speech synthesis");
                return;
            }

            try {
                const utter = new SpeechSynthesisUtterance(text);
                utter.lang = 'en-US';

                utter.onerror = function (event) {
                    console.error("Speech synthesis error:", event);
                };

                speechSynthesis.speak(utter);
            } catch (error) {
                console.error("Error in speech synthesis:", error);
            }
        }

        // --- Push to Talk Recording and Upload ---
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob;
        const pushToTalkBtn = document.getElementById('pushToTalkBtn');
        const audioPlayback = document.getElementById('audioPlayback');
        const statusSpan = document.getElementById('status');
        const userText = document.getElementById('userText');
        const aiText = document.getElementById('aiText');

        pushToTalkBtn.onmousedown = async function () {
            audioChunks = [];
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
                mediaRecorder.onstop = () => {
                    audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    audioPlayback.src = URL.createObjectURL(audioBlob);
                    audioPlayback.style.display = 'block';
                    // Automatically upload and process
                    uploadAndAsk();
                };
                mediaRecorder.start();
                pushToTalkBtn.textContent = 'Release to Send';
                statusSpan.textContent = 'Recording...';
            } catch (err) {
                statusSpan.textContent = 'Microphone access denied.';
            }
        };
        pushToTalkBtn.onmouseup = function () {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                pushToTalkBtn.textContent = 'Push to Talk';
                statusSpan.textContent = 'Processing...';
            }
        };
        async function uploadAndAsk() {
            if (!audioBlob) return;
            statusSpan.textContent = 'Uploading and processing...';
            userText.textContent = '...';
            aiText.textContent = '...';
            const formData = new FormData();
            formData.append('audio', audioBlob, 'voice.webm');
            try {
                const response = await fetch('/api/voice-chat', {
                    method: 'POST',
                    body: formData
                });
                if (!response.ok) throw new Error('Server error');
                const result = await response.json();
                userText.textContent = result.transcription || '(No transcription)';
                aiText.textContent = result.text || '(No AI response)';
                if (result.audioBase64 && result.audioMime) {
                    audioPlayback.src = `data:${result.audioMime};base64,${result.audioBase64}`;
                    audioPlayback.style.display = 'block';
                    audioPlayback.play();
                } else {
                    audioPlayback.style.display = 'none';
                }
                statusSpan.textContent = 'Done.';
            } catch (err) {
                statusSpan.textContent = 'Error: ' + err.message;
            }
        }
    </script>
</body>

</html>